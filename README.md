# Data Science & Machine Learning Portfolio
Welcome to my portfolio of data mining and machine learning projects! This repository contains a collection of my work from my MSc in Data Science at Vellore Institute of Technology, showcasing a range of skills from data preprocessing and exploratory data analysis to advanced model implementation and evaluation.

## Table of Contents
**01: EDA and Preprocessing**
This project focuses on the essential first steps of any data science workflow. Key concepts include: Data Cleaning, Feature Scaling, Handling Missing Values, and creating initial Visualizations to understand the dataset.
**02: Regression Models**
An exploration into predictive modeling for continuous values, this section covers the implementation and evaluation of both Linear and Polynomial Regression models.
**03: Classification Models**
This project deals with predicting categorical outcomes. Key models implemented include Logistic Regression for binary classification and Softmax Regression for multi-class problems.
**04: Gradient Descent from Scratch**
A deep dive into the foundational optimization algorithm that powers many machine learning models. This includes hands-on implementation of Batch, Stochastic, and Mini-Batch Gradient Descent.
**05: Decision Trees and SVMs**
This section explores two powerful and distinct modeling approaches: the rule-based Decision Tree (for both Classification and Regression) and the margin-based Support Vector Machine (SVM).
**06: Model Evaluation Metrics**
Understanding how to measure a model's performance is critical. This project covers key evaluation techniques, including the Confusion Matrix, ROC/AUC Curve, Precision, Recall, and the F1-Score.
**07: Ensemble Methods**
This project showcases how combining multiple models can lead to superior performance. Techniques covered include Bagging, Pasting, Random Forests, and Voting Classifiers.
**08: Gradient Boosting & Regularization**
An exploration of advanced modeling techniques, including the powerful AdaBoost and Gradient Boosting algorithms, as well as regularization methods like Ridge (L2) and Lasso (L1) to prevent overfitting.
**09: SVM Kernels and Dimensionality Reduction**
This section dives deeper into SVMs by exploring different kernel functions (Linear, Polynomial, RBF) and covers Principal Component Analysis (PCA) as a technique for dimensionality reduction.

## Technologies & Libraries Used
**Language**: Python
**Libraries:**
- Pandas
- NumPy
- Scikit-learn
- Matplotlib
- Seaborn
- Jupyter

**How to Run This Project**

1. Clone the repository:
git clone [https://github.com/Harneet9602/Machine-Learning-Portfolio.git](https://github.com/Harneet9602/Machine-Learning-Portfolio.git)

2. Install the required dependencies:
pip install -r requirements.txt

3. Navigate to the notebooks directory and open any assignment folder to view the Jupyter Notebooks.
